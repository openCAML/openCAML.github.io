{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we're going to look at how to implement linear regression. We're going to look at the 1-dimensional case, where we use a single feature to estimate the value of a related variable. Once you're comfortable with the single-variable case, try our notebook on linear regression with multiple features!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Python modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Data for Univariate Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 100 #Number of observations in the training set\n",
    "\n",
    "#Assign True parameters to be estimated\n",
    "trueIntercept = 10\n",
    "trueGradient = -4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.random.uniform(0, 100, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = trueIntercept + trueGradient*x + np.random.normal(loc=0, scale=40, size = n) #This is the true relationship that we're trying to model\n",
    "data = pd.DataFrame({'X':x, 'Y':y}) #Put the two arrays into a dataframe to make it easy to work with\n",
    "data.head(10) #Inspect the first ten rows of our dataset "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quickly plot the data so that we know what it looks like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(data['X'], data['Y'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There appears to be a fairly linear relationship between height and weight in this dataset. Linear regression therefore appropriate without doing feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Algebra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To fit a linear regression model to data $(x_1, y_1), (x_2, y_2),..., (x_n, y_n)$ such that $y_i = \\alpha + \\beta x_i + \\epsilon_i$, where $\\epsilon_i$ is the ith error term, the Least-Squares estimates for the parameters $\\alpha, \\beta$ are: \n",
    "\n",
    "\n",
    "$$\\hat \\beta = \\frac{\\sum^{n}_{i=1}(x_i - \\bar x)(y_i - \\bar y)}{\\sum^{n}_{i=1}(x_i - \\bar x)^2}$$ \n",
    "\n",
    "$$\\hat \\alpha = \\bar y - \\hat \\beta \\bar x $$\n",
    "\n",
    "Once we've calculated $\\hat \\alpha \\& \\hat \\beta$ we can estimate the label corresponding to a newly observed feature, $x^*$ as:\n",
    "\n",
    "$$ \\hat y = \\hat \\alpha + \\hat \\beta \\times x^* $$\n",
    "\n",
    "\n",
    "### How did we arrive at these values?\n",
    "\n",
    "The short answer is: Multivariate Calculus! There are lots of existing resources online which do a good job of explaining how we derive the equations for linear regression - check out [this link](https://towardsdatascience.com/linear-regression-derivation-d362ea3884c2) if you want to read more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegression1D:\n",
    "    \n",
    "    def __init__(self, data, target, feature, trainTestRatio = 0.9):\n",
    "        #data - a pandas dataset \n",
    "        #target - the name of the pandas column which contains the true labels\n",
    "        #feature - the name of the pandas column which we will use to do the regression\n",
    "        #trainTestRatio - the proportion of the entire dataset which we'll use for training\n",
    "                    #   - the rest will be used for testing\n",
    "        \n",
    "        self.target = target\n",
    "        self.feature = feature\n",
    "        \n",
    "        #Split up data into a training and testing set\n",
    "        self.train, self.test = train_test_split(data, test_size=1-trainTestRatio)\n",
    "        \n",
    "        \n",
    "    def fitLR(self):\n",
    "        #Estimate the model parameters (alpha and beta) from the training data\n",
    "        \n",
    "        pass\n",
    "    \n",
    "    def predict(self,x):\n",
    "        #Given a vector of new observations x, predict the corresponding target values\n",
    "        \n",
    "        pass\n",
    "    \n",
    "\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The process should work as follows:\n",
    "\n",
    "1. Create an instance of the class LinearRegression1D and pass it some data\n",
    "2. Fit a model to the training data (the training and testing data should have been automatically created) by calling the fitLR method\n",
    "3. Predict the target value for each observation in the testing data and see how you did. Alternatively you can plot the estimate line of best through the testing data for visual inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myModel = LinearRegression1D(data, 'Y', 'X')\n",
    "myModel.fitLR() #If this returns a zero, then it should have finished. If not we've got problems!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now let's see how we did! \n",
    "\n",
    "We can print the parameters we estimated for the gradient and intercept. Recall that the true values are saved as trueIntercept and trueGradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'The true intercept value was {trueIntercept}, we estimated the value to be {myModel.alphaHat}')\n",
    "print(f'The true gradient value was {trueGradient}, we estimated the value to be {myModel.betaHat}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not too bad! We didn't have a particularly large dataset to train on so to be in the right ballpark with the parameters is perfectly acceptable, given the variability within the data. A larger dataset would most likely give a more accurate estimation of the two values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's plot the line we have calculated against our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(np.floor(data['X'].min()), np.ceil(data['X'].max()))\n",
    "\n",
    "plt.scatter(data['X'], data['Y'], label = 'Data')\n",
    "plt.plot(x, myModel.alphaHat + x*myModel.betaHat, label = 'Regression line')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that our regression line runs through the centre of the point cloud, indicating that the model fits nicely."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## As a final check, lets plot the residuals (the error for each prediction) and see what they look like. Hopefully they will be evenly scattered either side of 0 - if not, then our model is biased and our predictions will probably be consistently biased (perhaps as a result of overfitting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testPred = myModel.predict(myModel.test[myModel.feature]) #What our models thinks the true values of y are, given x\n",
    "residuals = testPred - myModel.test[myModel.target]\n",
    "\n",
    "plt.scatter(list(range((residuals.shape[0]))), residuals)\n",
    "plt.ylabel('Residuals')\n",
    "plt.xlabel('index')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (cgvae)",
   "language": "python",
   "name": "cgvae"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
